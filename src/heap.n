// ---------------- DEFINITIONS ----------------

//some info
/*
    ================================================ INFORMATION ================================================
    |                                                                                                           |
    | I] INTRODUCTION                                                                                           |
    |                                                                                                           |
    | In this allocator, PC means "Page Collection".                                                            |
    |                                                                                                           |
    | A PC is nothing more than a mmap (using mmap syscall).                                                    |
    | It is a segment of heap allocated memory, with a total length that can only be a multiple of PAGE_SIZE.   |
    | Mind that this program uses MM__PAGE_SIZE as constant for his computation:                                |
    |     Please check that this one is correctly set or you will surely have undesired behavior !!!            |
    |                                                                                                           |
    | Also, in the following explanations, I will talk a bit about some technical concepts like CPU cache and   |
    | memory paging but only in surface, no deep dive will be given as it is not the subject of this project.   |
    |                                                                                                           |
    | Last thing before starting: mind that I am mainly considering "PC" instead of "page" or "cache" in these  |
    | paragraphs. It makes a real difference ! System and hardware may deal with different kind of units that   |
    | they will consider "local" to work with. This allocator works with Page Collections as their "local"      |
    | memory regions available.                                                                                 |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | II] GLOBAL ACCESS TO ALLOCATOR                                                                            |
    |                                                                                                           |
    | The algorithm of that allocator relies on the use of a static pointer "heap_latestPC", which seems to be  |
    | a security issue as it can be predictable to target in the DATA section of our program. This will should  |
    | fixed later using some more low-level contraptions (make everyone use a global stack value for example).  |
    |                                                                                                           |
    | For the moment, we need this static field to give every scope access to the allocator. Indeed, as memory  |
    | allocation should be accessible from any scope, anywhere, we have to keep somewhere a reference to some   |
    | allocator resources, ALWAYS ACCESSIBLE.                                                                   |
    |                                                                                                           |
    | In this allocator, the "global accessible" resource that must be shared with every other scope is a       |
    | reference to the latest PC created. This is the starting point of each new/free() execution.              |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | III] FULL STACK ALLOCATION                                                                                |
    |                                                                                                           |
    | If your program does not call any new/free, no PC will be created at all, you will be in full-stack       |
    | allocation. As soon as you call new(), you will create a first PC, and so, use some heap allocation.      |
    |                                                                                                           |
    | This algorithm is "infinitely providing", meaning that you can allocate memory as much as you need,       |
    | without any fixed limit or anything. The only way to have this end is to have the system refusing to give |
    | more when asking for new PC (=mmap) via syscalls.                                                         |
    |                                                                                                           |
    | In those cases, an error message will be printed in stderr and the program will exit with a specific      |
    | error code (everything set as constants in the header file).                                              |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | IV] LOCALITY / WASTE COMPROMISE                                                                           |
    |                                                                                                           |
    | By accessing any PC, we can access every other one that has been created from the beginning of the        |
    | program because they are chained together. By the way, this chain is made only in one sens, each PC       |
    | holding a reference to the PREVIOUS one only.                                                             |
    |                                                                                                           |
    | Why ? LOCALITY ! To preserve CPU from loading memory pages in cache (which can be time consuming and      |
    | inefficient), we should try to use the most recent memory chunks as much as possible. This is LOCALITY.   |
    | If we have to look for something in another PC, at least we should look in the PREVIOUS one first because |
    | it is the most recent memory space we used so it may still be in cache (no load to operate).              |
    |                                                                                                           |
    | This is also the reason why I decided to always keep THE LATEST PC address as global access to allocator, |
    | to always give priority to the latest PC when looking for a new allocation. That way, we ensure maximum   |
    | LOCALITY, trying to work on the same PC (=> page) as our latest allocated blocks.                         |
    |                                                                                                           |
    | HOWEVER, having only this does not always offer the best place for our new allocation as the "best fit"   |
    | algorithm says. It even goes a bit in contradiction with it and can lead to huge memory waste because of  |
    | the impossibility of re-using freed memory efficiently. Let's see this in detail.                         |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | V] RECALL ON THE MAIN PRINCIPLE OF "BEST-FIT"                                                             |
    |                                                                                                           |
    | Recall on the "best fit" main principle:                                                                  |
    |                                                                                                           |
    |   The "best fit" main principle is related to the SIZE of the chunks we want to allocate.                 |
    |   During the lifetime of a program, we will have some free slots available somewhere in a mmap or another |
    |   (in our case, in a PC or another, exactly the same thing).                                              |
    |                                                                                                           |
    |   These slots offer contiguous memory that could fit for new allocations with the exact same size OR it   |
    |   can also fit for SMALLER chunks. Therefore, the more a chunk to be allocated is BIG, the harder it will |
    |   be to find somewhere to put it.                                                                         |
    |                                                                                                           |
    |   Also, if a small chunk is allocated in a large freed area instead of somewhere else, we will no longer  |
    |   be able to use that large area for large allocations. Instead, we will have to use more memory pages    |
    |   (=> mmap, or PC in our case). This is ineficient as we end with:                                        |
    |     - Waste of unused memory                                                                              |
    |     - Bigger system resource usage                                                                        |
    |     - Slower execution (new page allocation implies syscall => kernel interupt... => CPU time!)           |
    |                                                                                                           |
    |   The "best fit" algorithm solves these issues by going over EVERY free chunk available and then :        |
    |     > if current chunk has exact size => use it (can't have better, stop research here)                   |
    |     > if current chunk is at least the desired size:                                                      |
    |        > check whether it is SMALLER than the latest potential match:                                     |
    |          - Definitely smaller => set as new potential                                                     |
    |          - Not smaller        => skip it                                                                  |
    |                                                                                                           |
    |   At the end, the best potential slot remains, so we are using the smallest chunk that can contain our    |
    |   data, leaving the big chunks for bigger data. If we weren't able to find any potential, that means we   |
    |   have no place to hold that chunk, so we have to allocate more pages.                                    |
    |                                                                                                           |
    | In our case, using the best fit principle would implie to go through every PC to check whether we have a  |
    | better place to re-use some memory. The problem is... if we do so, we will go and read over different     |
    | pages, potentially tons of them, so we are being inefficient in terms of locality (maximize page miss).   |
    | Therefore, we have used an alternative strategy to try keeping both sides efficient as much as possible.  |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | V] "BEST-FIT-BET" STRATEGY                                                                                |
    |                                                                                                           |
    | Trying to get the best locality while also saying that you will have the "best fit" together is like      |
    | saying that you will take the best card from a game that is split in several rooms, but you can't go into |
    | these rooms to check this out. This is a bet. Seems completely random... isn't it ?                       |
    |                                                                                                           |
    | Well, even if we can't be sure at 100%, we can at least reduce the risk by making a "best-fit-bet".       |
    | Let's take our previous methophore with rooms to explain this strategy here:                              |
    |                                                                                                           |
    |   In each PC, you have potental free space available for your data.                                       |
    |   It is like having available storage drawers in different rooms that can potentially fit to the object   |
    |   you want to store, but you can't know which drawer will fit the best (avoid wasting place if we have a  |
    |   bigger object later).                                                                                   |
    |                                                                                                           |
    |   Also, you would like to avoid going into every room because it will cost a lot of time to do so.        |
    |   The only thing you know is that you have an object with a certain size, and one room, the lastest room  |
    |   used, and the drawers available in that room.                                                           |
    |                                                                                                           |
    |   To reduce to risk of wasting large space, the "best-fit-bet" strategy will consider 2 cases and make a  |
    |   choice depending on the size of the element to be stored:                                               |
    |                                                                                                           |
    |     > Either we will bet on LOCALITY over best-fit (choose local slot, whatever is in other PCs)          |
    |                 or                                                                                        |
    |     > Pay the price to look in the previous PC for a better place.                                        |
    |                                                                                                           |
    | To decide whether to bet on locality or not, we will consider the available slots in our current PC where |
    | our data can be stored UNTIL A FIXED RANGE in bytes. For a certain size of data to be stored, we make a   |
    | difference between the "tiny bit bigger" slots and the "VERY MUCH BIGGER" slots.                          |
    | This threshold is configurable via the constant HEAP__BEST_FIT_BET__THRESHOLD.                            |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | VI] "BEST-FIT-BET" CHOSING LOCALITY                                                                       |
    |                                                                                                           |
    | If the data we want to store founds an available free slot IN CURRENT PC that is greater than what we     |
    | need, we will do as best-fit does, keeping track of this slot as potential fit, BUT, we also check        |
    | whether it is in the allowed range:                                                                       |
    |                  availableChunkSize > size(dataToStore) + HEAP__BEST_FIT_BEST_THRESHOLD                   |
    |                                                                                                           |
    | We keep both the best potential match that is IN THAT RANGE, and the best potential match OUT OF RANGE.   |
    | Then, after having these 2 potentials, we are now able to make a choice:                                  |
    |                                                                                                           |
    | If there is a potential IN RANGE, that means, we have a free slot in our local PC that is a bit bigger    |
    | than what we need, but also not SO big, so we might not waste that much space by using it.                |
    |                                                                                                           |
    |    => Bet on LOCALITY, we potentially have better somewhere else, but it won't be SO MUCH waste.          |
    |                                                                                                           |
    | Otherwise, we will consider having too big free slots in that PC (or no one available actually), so we    |
    | won't take the risk of wasting too much memory yet. In that case, we choose the NEIGHBOR CHECK option.    |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | VII] "BEST-FIT-BET" CHOSING NEIGHBOR CHECK                                                                |
    |                                                                                                           |
    | In this other case, we are sure that our latest PC does not have an IN RANGE SLOT, so we hope that we can |
    | find one in previous PCs. So, as we did in the local check, we will go over free slots of the previous PC |
    | trying to find out a potential IN RANGE slot.                                                             |
    |                                                                                                           |
    | If we don't find any IN RANGE slot in that previous PC neither, we move on again to the previous one      |
    | until no more PC can be found. The first IN RANGE slot available will be considered efficient enough (as  |
    | we considered in local research, this is a bet). Even if we are not checking EVERY PC, we consider it is  |
    | enough efficient for us.                                                                                  |
    |                                                                                                           |
    | If at the end of all pages, we still don't find any IN RANGE slot that could fit, we still can re-use     |
    | memory by taking one of the OUT RANGE slots we have found during analysis. For that reason, when we look  |
    | for potentials in a PC, we not only keep track of the best IN RANGE only but also the best OUT RANGE.     |
    |                                                                                                           |
    | It doesn't matter whether this OUT RANGE is from the local PC or not, we keep only the best one, whatever |
    | PC it is located on. So if no IN RANGE found, use the best OUT RANGE. But if no OUT RANGE has been found  |
    | at all ? Well that means we don't even have one slot that fits with our data requirement so we have to    |
    | allocate more to hold that memory item.                                                                   |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | VIII] "BEST-FIT-BET" EXACT MATCH INTERRUPTION                                                             |
    |                                                                                                           |
    | It is important to recall that, as "best-fit" implies, if an EXACT match is found during slot research,   |
    | (both local or neighbor research), WE ARE USING THIS EXACT SLOT: this is DEFINITELY the best fit for our  |
    | data. Everything stops here and we allocate this slot for the given data, without asking further          |
    | questions.                                                                                                |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | IX] "BEST-FIT-BET" NEIGHBOR CHECK LIMIT (technical!)                                                      |
    |                                                                                                           |
    | We could have stopped our neigbourg check here, and it would be nice. However, there is a tiny small      |
    | feature that we have also added to this allocator to still preserve maximum locality, even in neighbor    |
    | check: NEIGHBOR LIMIT.                                                                                    |
    |                                                                                                           |
    | When looking for the best IN or OUT RANGE in neighbor PCs, you may find the best place far away from the  |
    | latest PC. But actually, having a page miss because the available slot is 2 or 3 pages away will involve  |
    | the same delay as if it was 10 or 30 pages away.                                                          |
    |                                                                                                           |
    | In all cases, having to change PC seems to have the same impact, no matter how far in previous PCs we     |
    | found a slot to re-use. Well, this is not exactly true. Depending on your hardware and the size of your   |
    | CPU cache, you are probably able to load several PCs at once and so the impact of going to one PC or      |
    | another will be the same. Same locality, no additionnal load to operate.                                  |
    |                                                                                                           |
    | That means, even if we don't go slower by going far away in PCs, we can still go faster by limiting our   |
    | neighbor check to only a certain number of PCs. This will reduce the performance of "best-fit" as we      |
    | shorthen the number of PCs to be accessed but it allows you to guarantee an optimal locality.             |
    |                                                                                                           |
    | This is the role of the constant HEAP__BEST_FIT_BET__NEIGHBOR_LIMIT. It corresponds to the maximum number |
    | of PCs we allow to switch in neighbor check before considering we are going too far.                      |
    |                                                                                                           |
    | This kind of feature however, may be useful ONLY with programs that allocate a lot !                      |
    |                                                                                                           |
    | In these particular case, we may have a huge number of PCs, so locality over several PCs makes more sens  |
    | over "best-fit". Current execution may be not only centered on a few pages for everything, but rather on  |
    | the N latest PCs. Then, if you omit the N-1 previous PCs, it might be even better for you because no one  |
    | is using these pages for the moment (and they might no longer be in cache by the way).                    |
    |                                                                                                           |
    |            ============================ /!\ WARNING /!\ ================================                  |
    |          USING NEIGHBOR CHECK LIMIT UNEFFICIENTLY CAN CAUSE MORE DRAWBACKS THAN IMPROVEMENT !!!           |
    |          BY DEFAULT AND TO AVOID MISUSE, THIS FEATURE IS DISABLED. UNCOMMENT THE LINE BELOW               |
    |          TO ENABLE IT:                                                                                    |*/
//                              #define HEAP__BEST_FIT_BEST__NEIGHBOR_LIMIT_ENABLED
/*  |            =============================================================================                  |
    |                                                                                                           |
    |                                                                                                           |
    |                                                                                                           |
    | X] PC COMPOSITION                                                                                         |
    |                                                                                                           |
    | Each PC starts with 2 ulng of metadata:                                                                   |
    ||
    ||
    ||
    =============================================================================================================
*/

//pad every allocation request into a multiple of sizeof(ulng)
#define HEAP__PAD_ALLOC_LEN_ULNG

//best-fit-bet !WARNING: CHECK EXPLANATIONS ABOVE BEFORE MODIFYING
#define HEAP__BEST_FIT_BET__THRESHOLD      8
#define HEAP__BEST_FIT_BET__NEIGHBOR_LIMIT 18446744073709551616

//memory access
#define HEAP__ILLEGAL_ACCESS_OUTPUT //comment to disable output msg on illegal access






/* ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ALLOCATOR ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                              Allocator by I.A.

        This program is a bare metal library that allows you to allocate and free
    memory dynamically on linux systems, the same way as malloc/free does in
    standard C libraries.

        Of course, as it is the main goal of this library, this implementation is
    completely independant from any C library related resources and stands only
    by using linux syscalls.

    Contact: https://github.com/stark-os

    Let's Code !                                  By I.A..
******************************************************************************************

    LICENSE:

    stark-os/dev/core/heap
    Copyright (C) 2025 Sebastien SILVANO

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library.

    If not, see <https://www.gnu.org/licenses/>.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ */






// ---------------- GENERIC TOOLS ----------------

//padding tool, pads the given value to the next multiple of the power of 2:
//    37,4096 => 4096
//  2000,4096 => 4096
//  4096,4096 => 4096
//  4097,4096 => 8192
//  8191,8192 => 8192
//  ...
ulng padP2(ulng n, ulng p2) { return (n + p2 - 1) & ~(p2 - 1); }






// ---------------- PC SCALE ----------------

//latest PC
ulng* heap__latestPC = null;



//new - free PC
static ref heap__newPC(ulng len) {



	//STEP 1: ALLOCATE

	//need 5 additionnal ulng than requested: 3 for PC metadata (prev PC + freeLstRef + PC size), 2 for allocated block metadata (len + freeLst ref)
	ulng PCLen = len + 5*sizeof(ulng);

	//pad len asked, and also deduce remaining space left (can be 0 btw)
	ulng paddedPCLen   = padP2(PCLen, MM__PAGE_SIZE);
	ulng remainingInPC = paddedPCLen - PCLen;

	//allocate new page(s)
	ulng* pc = syscall_mmap(
		null,        //adr
		paddedPCLen, //len
		MM__PROT_READ   | MM__PROT_WRITE,    //prot
		MM__MAP_PRIVATE | MM__MAP_ANONYMOUS, //flags
		-1, //fd
		0   //offset
	);

	//system refuses => stop program
	if(pc == MM__MAP_FAILED){
		syscall_write(STDERR, "[ ERROR ] > Unable to allocate more memory for process.", 59);
		syscall_exit(ERR__SYSTEM_REFUSE_ALLOC);
	}



	//STEP 2: CHAIN

	//save PC size also
	pc[2] = paddedPCLen;

	//chain with other PCs: 1st ulng of PC contains prev PC adr
	pc[0]          = (ulng)heap__latestPC;
	heap__latestPC = pc;                   //update latestPC, now we are working on this new one in priority now



	//STEP 3: SET INITIAL FREE LST (inside PC)

	//too few space left => let's give the remaining to our data
	ulng* firstFreeSlot = null;
	if(remainingInPC < 2*sizeof(ulng)){ len += remainingInPC; } //<-------- !WARNING IF USING "HEAP__PAD_ALLOC_LEN_ULNG": Will make "len" unpadded with sizeof(ulng) if MM__PAGE_SIZE is not a multiple of size(ulng).

	//enough space => create 1st slot with it
	else{
		firstFreeSlot    = pc + 4 + len;                   //2 metadata for PC + 2 metadata for allocated block + len of allocated block
		firstFreeSlot[0] = remainingInPC - 2*sizeof(ulng); //slot size (available space - 2 metadata ulng for the potential new block to be set here)
		firstFreeSlot[1] = (ulng)null;                     //next slot adr (none here)
	}

	//set initial freeLst
	pc[1] = (ulng)firstFreeSlot;

	//set allocated region
	pc[3] =          len; //size            as 1st ulng in allocated chunk (4th ulng in PC)
	pc[4] = (ulng)(pc+1); //freeLstHead ref as 2nd ulng in allocated chunk (5th ulng in PC)
	return pc+5;          //adr             as 3rd ulng in allocated chunk (6th ulng in PC)
}

static void heap__freePC(ref adr, ulng len) {
	if(syscall_munmap(adr, len) == -1){
		syscall_write(STDERR, "[ ERROR ] > Unable to de-allocate memory from process.", 54);
		syscall_exit(ERR__SYSTEM_REFUSE_FREE);
	}
}






// ---------------- USER SCALE ----------------

//size
ulng heap__sz(ref r){ return (((ulng*)r)-2)[0]; }



//new - free
ref heap__new(ulng len){

	//0 bytes to allocate => silent err
	if(!len){ return null; }

	#ifdef HEAP__PAD_ALLOC_LEN_ULNG
	//padding to only multiple of ulng
	len = padP2(len, sizeof(ulng));
	#else
	//at least sizeof(ulng) bytes required to allocate
	if(len < sizeof(ulng)) { len = sizeof(ulng); }
	#endif

	//potential matches: IN RANGE
	ulng* bestPtl_inRange_prevRef = null;
	ulng* bestPtl_inRange         = null;
	ulng  bestPtl_inRange_size    = 0;

	//potential matches: OUT RANGE
	ulng* bestPtl_outRange_prevRef     = null;
	ulng* bestPtl_outRange             = null;
	ulng  bestPtl_outRange_size        = 0;
	ulng* bestPtl_outRange_freeLstHead = null;

	//neighbor limitation
	#ifdef HEAP__BEST_FIT_BEST__NEIGHBOR_LIMIT_ENABLED
	ulng PCnbr = 0;
	#endif

	//all researches at once
	ulng* curPC = heap__latestPC; //start by a LOCAL search
	while(curPC != null){
		ulng* curPC_freeLstHead   = curPC+1;
		ulng* curFreeSlot_prevRef = curPC_freeLstHead;
		while(true){

			//as long as we have a free slot
			if(!curFreeSlot_prevRef){ break; }

			//cur free slot
			ulng* curFreeSlot = (ulng*)(curFreeSlot_prevRef[0]);
			ulng  size        = curFreeSlot[0]; //size of free block as 1st ulng inside slot

			//exact match => use it
			if(size == len){
				curFreeSlot_prevRef[0] = curFreeSlot[1];          //disconnect slot from freeLst, <=> prevSlot->nxt = curSlot->nxt
				curFreeSlot[1]         = (ulng)curPC_freeLstHead; //set freeLstHead in newly allocated block
				return curFreeSlot+2;                             //direct return adr, no need to set the size (exact match)
			}

			//bigger => potential
			if(size > len){

				//in-range => update best potential
				if(size < len + HEAP__BEST_FIT_BET__THRESHOLD){
					if(size < bestPtl_inRange_size){
						bestPtl_inRange_size    = size;
						bestPtl_inRange_prevRef = curFreeSlot_prevRef;
						bestPtl_inRange         = curFreeSlot;
					}
				}

				//out-range => update best potential
				else {
					if(size < bestPtl_outRange_size){
						bestPtl_outRange_size        = size;
						bestPtl_outRange_prevRef     = curFreeSlot_prevRef;
						bestPtl_outRange             = curFreeSlot;
						bestPtl_outRange_freeLstHead = curPC_freeLstHead;
					}
				}
			}

			//next free slot adr as 2nd ulng inside slot
			curFreeSlot_prevRef = (ulng*)(curFreeSlot[1]);
		}

		//in-range slot found in that page => use it
		if(bestPtl_inRange){
			bestPtl_inRange_prevRef[0] = bestPtl_inRange[1];      //disconnect slot from freeLst, <=> prevSlot->nxt = bestPtl_inRangeSlot->nxt
			bestPtl_inRange[0]         = bestPtl_inRange_size;    //set size        in newly allocated block
			bestPtl_inRange[1]         = (ulng)curPC_freeLstHead; //set freeLstHead in newly allocated block
			return bestPtl_inRange+2;
		}

		//go to previous PC (neighbor check)
		curPC = (ulng*)curPC[0];

		//limit reached
		#ifdef HEAP__BEST_FIT_BEST__NEIGHBOR_LIMIT_ENABLED
		PCnbr++;
		if(PCnbr == HEAP__BEST_FIT_BEST__NEIGHBOR_LIMIT){ break; }
		#endif
	}

	//still no exact match or in-range potential found => use out-range potential
	if(bestPtl_outRange){
		bestPtl_outRange_prevRef[0] = bestPtl_outRange[1];                //disconnect from freeLst, <=> prevSlot->nxt = bestPtl_outRangeSlot->nxt
		bestPtl_outRange[0]         = bestPtl_outRange_size;              //set size        in newly allocated block
		bestPtl_outRange[1]         = (ulng)bestPtl_outRange_freeLstHead; //set freeLstHead in newly allocated block
		return bestPtl_outRange+2;
	}

	//no even having any out-range potential => allocate new PC
	return heap__newPC(len);
}

void heap__free(ref r){
	ulng* freedSlot  = ((ulng*)r)-2;
	ulng* tgtFreeLst = (ulng*)(freedSlot[1]);



	//CASE 1: MERGING WITH PREV/NEXT SLOTS

	//adr right after our block
	ulng* followingAdr = freedSlot + freedSlot[0] + 2*sizeof(ulng);

	//go over the whole freeLst for that PC
	ulng  totalFreeLstSize    = 0;     //total size of every free slots (including metadata)
	boo   mergedPrev          = false;
	boo   mergedNext          = false;
	ulng* prevNeedingUpdate   = null;
	ulng* curFreeSlot_prevRef = tgtFreeLst;
	while(true){

		//as long as we have anything in free lst
		if(!curFreeSlot_prevRef){ break; }

		//cur free slot
		ulng* curFreeSlot = (ulng*)(curFreeSlot_prevRef[0]);
		totalFreeLstSize += curFreeSlot[0] = 2*sizeof(ulng);

		//found free slot RIGHT BEFORE ours => merge them
		if(curFreeSlot + curFreeSlot[0] + 2*sizeof(ulng) == freedSlot){
			curFreeSlot[0] += freedSlot[0] + 2*sizeof(ulng); //add our complete freedSlot as raw available data in curFreeSlot

			//VERY IMPORTANT !!! If having both merge prev & after, freedSlot must be updated so that we will merge the prevMergedSlot with the next one.
			freedSlot = curFreeSlot;
			if(prevNeedingUpdate){ prevNeedingUpdate[0] = (ulng)curFreeSlot; } //also, the prevRef that has been updated must be updated once more to the even-before chunk (=current one) !

			//optimization
			if(mergedNext){ return; }
			mergedPrev = true;
		}

		//found free slot RIGHT AFTER ours => merge them also
		else if(followingAdr == curFreeSlot){
			freedSlot[0]          += curFreeSlot[0] + 2*sizeof(ulng); //add complete curFreeSlot as raw available data in our freedSlot
			freedSlot[1]           = curFreeSlot[1];                  //also take the "next" field from curFreeSlot
			curFreeSlot_prevRef[0] = (ulng)freedSlot;                 //<=> prevSlot->nxt = curSlot

			//keep aside the prevRef in case the following freeSlot is RIGHT BEFORE the freed one => we will have to update prevRef one more time
			prevNeedingUpdate = curFreeSlot_prevRef;

			//optimization
			if(mergedPrev){ return; }
			mergedNext = true;
		}

		//check next free slot
		curFreeSlot_prevRef = (ulng*)(curFreeSlot[1]);
	}

	//full PC has been freed => de-allocate memory
	ulng PCSize = (tgtFreeLst+1)[0];
	if(totalFreeLstSize + 3*sizeof(ulng) == PCSize){ //3 ulng of PC metadata + each free block occupies the whole PC
		heap__freePC(tgtFreeLst-1, PCSize);
		return;
	}

	//at least one merge => no need to go further
	if(mergedPrev || mergedNext) { return; }



	//CASE 2: CREATE INDEPENDANT SLOT (unmerged)

	//set free slot data (size is unchanged)
	freedSlot[1] = (ulng)(tgtFreeLst); //<=> curSlot->nxt = freeLstHead

	//add slot to free lst, as 1st element of lst (which means it will be accessed in priority in further allocations btw)
	tgtFreeLst[0] = (ulng)(freedSlot); //<=> freeLstHead = curSlot
}






// ---------------- MEMORY ACCESS ----------------

//unsafe: read
u8  heap__unsafe_ru8( iref ir){ return ((u8*)(  ((ubyt*)ir.base)+ ir.offset ))[0]; }
u16 heap__unsafe_ru16(iref ir){ return ((u16*)( ((ubyt*)ir.base)+ ir.offset ))[0]; }
u32 heap__unsafe_ru32(iref ir){ return ((u32*)( ((ubyt*)ir.base)+ ir.offset ))[0]; }
#ifdef ARCH64
u64 heap__unsafe_ru64(iref ir){ return ((u64*)( ((ubyt*)ir.base)+ ir.offset ))[0]; }
#endif


//unsafe: write
void heap__unsafe_wu8( iref ir, u8  e){ ((u8*)(  ((ubyt*)ir.base)+ ir.offset ))[0] = e; }
void heap__unsafe_wu16(iref ir, u16 e){ ((u16*)( ((ubyt*)ir.base)+ ir.offset ))[0] = e; }
void heap__unsafe_wu32(iref ir, u32 e){ ((u32*)( ((ubyt*)ir.base)+ ir.offset ))[0] = e; }
#ifdef ARCH64
void heap__unsafe_wu64(iref ir, u64 e){ ((u64*)( ((ubyt*)ir.base)+ ir.offset ))[0] = e; }
#endif



//safe: read
u8 heap__safe_ru8(iref ir){
	if(ir.offset > heap__sz(ir.base)){ //seems a bit stupid to make sizeof(u8), so used literal "1"

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal read U8 from heap.\n", 39);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_RU8);
	}
	return heap__unsafe_ru8(ir);
}

u16 heap__safe_ru16(iref ir){
	if(ir.offset+2 > heap__sz(ir.base)){ //seems a bit stupid to make sizeof(u16), so used literal "2"

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal read U16 from heap.\n", 40);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_RU16);
	}
	return heap__unsafe_ru16(ir);
}

u32 heap__safe_ru32(iref ir){
	if(ir.offset+4 > heap__sz(ir.base)){ //seems a bit stupid to make sizeof(u32), so used literal "4"

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal read U32 from heap.\n", 40);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_RU32);
	}
	return heap__unsafe_ru32(ir);
}

#ifdef ARCH64
u64 heap__safe_ru64(iref ir){
	if(ir.offset+8 > heap__sz(ir.base)){ //seems a bit stupid to make sizeof(u64), so used literal "8"

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal read U64 from heap.\n", 40);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_RU64);
	}
	return heap__unsafe_ru64(ir);
}
#endif



//safe: write
void heap__safe_wu8(iref ir, u8 e){
	if(ir.offset > heap__sz(ir.base)){

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal write U8 from heap.\n", 40);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_WU8);
	}
	return heap__unsafe_wu8(ir, e);
}

void heap__safe_wu16(iref ir, u16 e){
	if(ir.offset+2 > heap__sz(ir.base)){ //seems a bit stupid to make sizeof(u16), so used literal "2"

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal write U16 from heap.\n", 41);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_WU16);
	}
	return heap__unsafe_wu16(ir, e);
}

void heap__safe_wu32(iref ir, u32 e){
	if(ir.offset+4 > heap__sz(ir.base)){ //seems a bit stupid to make sizeof(u32), so used literal "4"

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal write U32 from heap.\n", 41);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_WU32);
	}
	return heap__unsafe_wu32(ir, e);
}

#ifdef ARCH64
void heap__safe_wu64(iref ir, u64 e){
	if(ir.offset+8 > heap__sz(ir.base)){ //seems a bit stupid to make sizeof(u64), so used literal "8"

		//optl output
		#ifdef HEAP__ILLEGAL_ACCESS_OUTPUT
		syscall_write(STDERR, "[ ERROR ] > Illegal write U64 from heap.\n", 41);
		#endif

		//spc err
		syscall_exit(ERR__ILLEGAL_HEAP_WU64);
	}
	return heap__unsafe_wu64(ir, e);
}
#endif



//variable size, unsafe: write
void heap__unsafe_w(iref src, iref dst, ulng size){
	for(ulng i=0; i < size; i++){ heap__unsafe_wu8(dst, heap__unsafe_ru8(src)); }
}



//variable size, safe: write
void heap__safe_w(iref src, iref dst, ulng size){
	for(ulng i=0; i < size; i++){ heap__safe_wu8(dst, heap__safe_ru8(src)); }
}
